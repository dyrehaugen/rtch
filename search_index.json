[["index.html", "Technology 1 Technology", " Technology Dyrehaugen Web Notebook 2023-12-22 1 Technology "],["airplanes.html", "2 Airplanes 2.1 Hydrogen Powered Airplanes", " 2 Airplanes 2.1 Hydrogen Powered Airplanes Galluchi About one-third of total passenger traffic worldwide could be carried by planes burning liquid hydrogen, based on 2019 route data according to a white paper. In the most optimistic scenario, aircraft powered by ​“green hydrogen” — produced using renewable electricity — could reduce total emissions from passenger flights by 31 percent compared to projected emissions levels in 2050. Aviation contributes about 2.5 percent of global greenhouse gas emissions every year, primarily from burning petroleum-based jet fuel, or kerosene. Some airlines are already chipping away at their emissions by blending their kerosene with small amounts of ​“sustainable aviation fuels,” or SAFs, which are primarily made today from used cooking oils and discarded animal fats. Producers and policymakers are pushing to drastically boost adoption of SAFs for commercial flights starting this decade, from about 26 million gallons every year to several billion gallons a year by 2030. Yet while plant- and waste-based alternatives can be cleaner to produce than jet fuel, they still emit carbon dioxide when burned in engines. Hydrogen does not — hence the industry’s intensifying efforts to develop H2-powered aircraft. Hydrogen planes could capture a huge share of shorter flights, but not long trips. Figure: Airbus Concept Planes Liquid hydrogen-powered aircraft would be less energy-efficient and have a shorter range than their kerosene-powered counterparts — making them impractical for long-haul flights without more technology innovations. However, the zero-emission planes could still service a sizable share of passenger air travel. A turboprop burning liquid hydrogen could transport 70 passengers up to 1,400 kilometers. A narrow-body aircraft could carry 165 passengers up to 3,400 kilometers. Hydrogen planes could service about 97 percent of the turboprop market and 71 percent of the narrow-body market. Liquid hydrogen packs much less energy on a volume basis than kerosene does, so planes would have to store more of it to travel the same distance. The zero-carbon fuel must also be kept at around -250 degrees Celsius in heavy cryogenic tanks, further weighing down the plane. In the two Airbus designs, the main bodies of the planes are elongated to accommodate the extra fuel storage. The world will need to build gigatons’ worth of additional wind, solar and other renewable energy capacity to produce enough green hydrogen to supply a zero-emission aircraft fleet — as well as to power the energy-intensive process of liquifying that hydrogen. Drop-in Fuels “Drop-in” fuels made of used cooking oil or forest residues represent less than 1 percent of total jet fuel demand. In Europe, aviation officials are pushing to accelerate the production and use of such fuels. The ReFuelEU Aviation proposal introduced last year would require that fuels delivered to European Union airports contain at least 2 percent SAF by 2025, ratcheting up to 63 percent by midcentury. Galluchi (2022) Hydrogen-powered planes could handle a third of passenger air travel "],["blockchain.html", "3 Blockchain 3.1 Land Registers", " 3 Blockchain Blockchain technology, the design of which was originally seen as facilitating an egalitarian, peer-to-peer sharing economy, is not necessarily neutral and apolitical. 3.1 Land Registers Daivirt There is a need for more empirical insights into the ways how blockchain-based property relations create new territories of accumulation and resistance, and intersect with existing legal and political systems. This essay explores the abstraction of blockchain as employed for formalizing land rights in emerging economies. Behind the seemingly neutral façade of the technology, diverse aspirational claims and narratives guide its implementation in different societies, shaped by particular histories and socio-political contexts. This highlights the need to explore blockchain-based land registries as distributed knowledge infrastructures, uncovering their broader embeddedness in older, non-digital modalities, and the “peopled infrastructures” of informal networks with their histories and cultural repertoires. As digital technologies can facilitate an illusion of enhanced visibility of some elements while obscuring others, I argue that more attention is needed to the role of broader colonial legacies and enduring North-South inequalities that frequently remain backgrounded in the adoption of such technologies. An increasing number of governments are investigating the prospects of transferring their land registries to blockchain. Blockchain applications are explored as enabling the formalization of property rights in the countries of the Global South, as well as providing more efficient coordination of real property markets in the Global North. Blockchain registries have several advantages as compared to centralized digital or paper-based databases. Records on blockchain are distributed and verified by a multitude of nodes in a peer-to-peer digital network, affording them more transparency and resilience. As new additions to the chain of blocks are cryptographically time-stamped, this makes tampering or accidental data loss less likely. Auto-executing “smart contracts” that transform legal agreements into code could mediate contracts Blockchain-based digitalization of land records should be viewed within a broader framework of land tenure formalization in the Global South, where land titling has been advocated as enabling economic development by turning land into tradable asset and a source of credit. Contrary to the expectations of the proponents of neoliberal land reforms, recent land titling initiatives in Africa and Latin America have fueled speculative investment and land concentration. Many communities in the Global South follow local, alternative rules of property, where land is held under customary tenure and managed as part of a complex system of obligations and debts within a broader kin or territorial group. Reforms that introduce exclusive land rights may exacerbate political conflicts especially in unstable and transitional settings. Daivirt (2021) Land, property, technology: interrogating an infrastructural promise "],["carbon-capture.html", "4 Carbon Capture 4.1 Low Scale Carbon Capture", " 4 Carbon Capture 4.1 Low Scale Carbon Capture CarbonQuest The room-sized CO2 filtration and liquefaction system, installed early this year by CarbonQuest, is a rare instance of carbon capture that actually works and delivers an economic payback. Power-plant or industrial-scale carbon capture has a long history of disappointing results. CarbonQuest captures emissions from existing heating systems, paying back the investment by avoiding penalties under New York’s carbon-reduction rules and selling industrial-grade CO2 to paying customers. CarbonQuest had tapped into the insulated duct that carries hot boiler exhaust to the chimney, diverting the flow through a circuitous array of hissing, humming machinery that pulls out moisture and isolates the carbon dioxide from nitrogen and oxygen, which get released back out the flue. The carbon dioxide then gets cooled to a liquid state and stored, under pressure, in a metal tank. Eventually, a truck pulls up on the street outside, connects a hose to a nozzle on the side of the building and sucks out the liquid carbon for delivery to a concrete factory, which will inject the greenhouse gas into concrete blocks, making them stronger. At its current scale, it catches 60 percent of the entire building’s gas emissions. Spector (2022) Carbon capture for New York high-rise apartments is a real thing now "],["concrete.html", "5 Concrete 5.1 Growing limestone from algae 5.2 Mud Constructions", " 5 Concrete We live in a world of concrete. After water, it’s the most widely used substance on our planet, and its usage around the world, ton for ton, is twice that of steel, wood, plastics and aluminium combined. Its invention in 1824, by a bricklayer in Leeds who first produced the Portland cement used to bind the aggregates used in concrete, quite literally paved the way for the creation of the modern world, enabling humans to mould high-strength, stone-like structures of almost any shape. Concrete’s ubiquity comes at a high price though: if the cement industry were a country, it would be the third-largest emitter of carbon dioxide in the world, after the US and China, as it releases over 2.8 billion tonnes into the atmosphere each year. A 2018 report suggested concrete contributes up to 8 per cent of the world’s CO2 emissions. It also requires phenomenal amounts of water, sucking up around a tenth of all water used in industry – often in areas with critical water shortages. Cockburn Major construction firms team up to get the carbon out of concrete Canary Media Engineers and architects can reduce the proportion of cement in a number of ways. One is to use higher-quality aggregate that imparts more structural integrity to the concrete that’s made with it. Another is by using what’s called ​“supplementary cementitious materials” to replace a portion of the cement used in different mixes of concrete. Fly ash from coal plants and slag from steel mills are the most common alternatives and are being put to use by some major cement and concrete companies such as Cemex. But rice husks, ground glass and several other alternatives can replace anywhere from 10 to 40 percent of the cement. Canary media (2022) Major construction firms team up to get the carbon out of concrete 5.1 Growing limestone from algae Simpkins To make portland cement, the most common type of cement, limestone is extracted from large quarries and burned at high temperatures, releasing large amounts of carbon dioxide. Replacing quarried limestone with biologically grown limestone, a natural process that some species of calcareous microalgae complete through photosynthesis (just like growing coral reefs), creates a net carbon neutral way to make portland cement. In short, the carbon dioxide released into the atmosphere equals what the microalgae already captured. Simpkins (2022) Cities of the future may be built with algae-grown limestone 5.2 Mud Constructions Lewis Concrete’s heat-retaining properties are all wrong for the Senegalese climate. Yet concrete has become the “traditional” building material in a country. At least four distinctive mud-construction techniques persist. In the north, where there’s not much rain, people build houses with banco, a kind of adobe made with sun-dried bricks; in the forested areas of the south, builders use timber frames to create wattle-and-daub structures, or they hand-mold earthen buildings and top them with steep, overhanging roofs to keep rain away from the walls. For generations, Senegalese builders have used mud to construct not only small houses and granaries but multistory houses and imposing mosques. Raw-earth-based building materials, such as adobe, rammed earth, and the compressed-earth blocks have more thermal inertia than concrete, which means they attenuate heat and cold more efficiently and reduce the need for so much air-conditioning. Resistance to mud construction in modern Senegal goes beyond practical concerns: Earth-based materials are widely considered a symbol of poverty, a last recourse for those with no other shelter. The accessibility of air-conditioning has created a kind of architectural laziness, because buildings no longer need to rely on design to stay cool. In the nearby village of Ngawlé, Ousmane Mbodj and his family invited me into their banco house, and as soon as I stepped inside, my body relaxed. I had no instruments to measure the difference in temperature, but the change felt like a balm. Thick walls provide natural insulation from the sun, while the limited number of small windows helps the interior stay cool. Outside, thatch-covered verandas or perforated walls create shade and can be used as exterior rooms. Roof leaks during the rainy season because the local mice like to eat its mud and hay. In the center of Podor, the local département is constructing a mud-brick administrative building using the Nubian-vault technique. Originating from ancient Egypt, the method uses arches to create self-supporting adobe structures. The technique was revived in the 1940s by the Egyptian architect Hassan Fathy, who attempted to create a whole village of Nubian-vault structures on the banks of the Nile River. That project was never completed, but his approach, which he documented in his book Architecture for the Poor, created new interest in mud construction across the globe. In 2000, a French nonprofit called the Nubian Vault Association streamlined the technique and started training workers to employ it throughout West Africa—starting in Burkina Faso and expanding to Mali, Benin, Ghana, and Senegal. An earth-construction boom is happening along the sunny coast south of Dakar. Here, earth construction is chosen not just by those with modest budgets and few other options, but by wealthier families with a taste for innovation and bespoke designs. They had planned to build nearly 12-inch-thick walls for their thermal advantages, but the small lot could only accommodate 9-inch-thick walls. To make up for the difference, they positioned each row of blocks so that it protruded slightly over the row below it, resulting in walls that essentially create their own shade. The walls’ textured surface gives them a unique appearance—a style inspired by substance. Though houses like this are far too expensive for most, it illustrates both the practical and aesthetic advantages of mud construction. Show people that we can build with local materials that will be much more comfortable and much cheaper than concrete. Lewis (2022) The Future of Mud "],["ethylene.html", "6 Ethylene", " 6 Ethylene Gallucci Ethylene is a key building block for many of the chemicals that go into everyday items, including diapers and detergent, fabrics and foams, mattresses and milk jugs, plastic bags, PVC pipes and even airplane wings. It is the most-used primary petrochemical in the world, accounting for about one-third of the industry’s global consumption. Today, making ethylene involves ​“cracking” apart the molecules in ethane or other hydrocarbons, which is done by burning huge amounts of fossil gas to heat giant furnaces to scorching temperatures. This step alone is responsible for 90 percent of the CO2 emissions associated with ethylene plants. At Chemelot, near the city of Geleen, the engineering firm Coolbrook is piloting a new kind of technology — one that uses only electricity to crack ethane. The European company recently began testing its electric-driven ethylene reactor, as part of a broader 12-million-euro ($12.7 million) initiative for decarbonizing industrial emissions. In September, Coolbrook successfully completed its first phase of large-scale testing at the site, using an electric heater that makes high-temperature process heat for chemical, cement and steel manufacturing. Globally, ethylene production totals around 160 million metric tons per year, resulting in more than 260 million metric tons of annual CO2 emissions. That’s roughly the climate equivalent of operating 70 U.S. coal-fired power plants for one year. The e-cracker concept is steadily gaining traction within the $5 trillion global chemical industry. The push to electrify ethylene production is a critical step toward reducing the climate impacts of chemical manufacturing, which accounts for about 15 percent of global industrial CO2 emissions every year. But e-crackers can’t address the inconvenient reality that, in its current form, ethylene is fundamentally problematic for the environment. First, ethane is primarily derived from fossil gas extraction or as a byproduct of petroleum refining. The fossil-based feedstock accounts for about one-third of ethylene’s total life-cycle emissions when measured from the point of raw material extraction to the stage when ethylene leaves the production plant, according to a 2020 analysis commissioned by the American Chemistry Council. Second, in addition to generating CO2 emissions, the process of cracking ethane gas releases significant amounts of cancer-causing air pollutants, including benzene, butadiene and naphthalene. A 2021 ProPublica investigation found that, across the United States, emissions from two dozen BASF-owned ethylene plants exposed an estimated 1.5 million Americans to elevated cancer risks. Ethane or other gaseous feedstocks are first mixed with steam inside a ​“turbomachine,” a type of technology also used in jet engines and gas turbines. By spinning a rotor shaft at supersonic velocity, then slowing it down, Coolbrook’s machine converts electrical energy into mechanical energy, then into thermal energy, which directly heats gas inside the reactor — reaching temperatures above 1,830°F (1,000°C). This creates the conditions needed to crack molecules to make ethylene. The concept dates back to at least the 1990s, when a team of rocket engineers began exploring using turbomachines to generate high-temperature process heat for making petrochemicals. Ethylene reactor can yield up to 20 percent more of the chemical when compared to traditional crackers that burn fossil gas to generate heat. Even if ethylene crackers were equipped to the hilt with pollution controls and were only made using non-fossil feedstocks, that still wouldn’t solve the third and perhaps biggest problem associated with the chemical’s production: Plastics made from ethylene and other ingredients are clogging the world’s waterways at unprecedented levels. Toxic chemicals from plastics are increasingly entering water supplies and our bloodstreams. Unless countries drastically curb consumption, annual plastic use is projected to nearly double by 2050. The multilayered challenge of tackling an industry that’s both highly polluting and integral to modern society. There’s no simple trick for cleaning up ethylene. Gallucci (2023) This key chemical is super dirty to make. Can an electric furnace help? "],["graphene.html", "7 Graphene 7.1 Graphene Microchips", " 7 Graphene 7.1 Graphene Microchips Kollewe Graphene, a 2D form of carbon, with the atoms arranged in a hexagonal structure, is mainly used to strengthen concrete and paints, but is now being touted as a replacement for silicon in semiconductors. China has started using it to get ahead in the global microchip wars. Graphene, hailed as a “super material”, is extracted from graphite, the crystalline form of carbon used to make pencils, and comes as a latticed sheet just one atom thick. Thomas believes it will “fundamentally change the world”, altering the way everything from mobile phones and computers to electric cars, healthcare and military equipment is manufactured. Smartphones made using the material could be worn on your wrist, and graphene tablets could be rolled up like a newspaper, according to the University of Manchester, where, in 2004, graphene was first produced. Potential uses include quantum computing, magnetic sensors in a new generation of MRI scanners, and consumer technology such as delivery drones. Graphene is one of the strongest and thinnest materials in existence, much tougher than steel but lighter than paper, harder than a diamond but more elastic than rubber. It is also highly effective at conducting heat and electricity. In its Somersham lab, two reactors – big boxes whose main part is shaped like a pizza oven – produce enough graphene to make 150,000 sensors a day. Paragraf uses the material in two ways: to measure magnetic fields, and to convert micro-organisms such as bacteria and viruses into electrical signals by combining graphene with a wet layer of chemistry as a biosensor. Paragraf has thrown its weight behind biosensors, which can detect the difference between viral and bacterial infections to determine whether a person needs antibiotics. It can also reveal the presence of conditions such as Covid-19, or spot infectious diseases in plants or animals. China has tried to corner the market in graphene. An estimated 5,000 companies are now working on graphene products there. Huawei uses graphene in its Pocket S clamshell phone, and Apple is reportedly testing graphene films for the iPhone 16, to avoid overheating. China even declared that it would mass-produce microchips by using graphene instead of silicon, making a full transition by 2025, though the claim was met with scepticism in the west. Kollewe (2023) Graphene will change the world’: the boss using the ‘supermaterial’ in the global microchip war "],["hydrogen.html", "8 Hydrogen 8.1 Nanocell fueltanks", " 8 Hydrogen 8.1 Nanocell fueltanks Ohnsman H2MOF thinks nanomaterials designed to pull in and hold hydrogen at low pressure, like a sponge absorbing water, are a cheaper, more efficient way to store and move the fuel. Hydrogen is a promising form of carbon-free energy, but moving and storing the superlight element is costly and energy-intensive. So a California startup cofounded in 2022 by two leading chemists, including a Nobel laureate, is designing a new type of tank made with nanomaterials that aims to be cheaper and safer than any currently in use — and hold more hydrogen, too. Rather than pumping highly compressed or liquified hydrogen into a conventional tank, H2MOF is designing one that holds the energy-rich fuel in a solid state, adsorbing it into specially engineered nanomaterials. The approach is based on research by two of its cofounders and scientific advisors: Omar Yaghi, a chemistry professor at the University of California, Berkeley, and professor Sir Fraser Stoddart, winner of the Nobel Prize in chemistry in 2016. It requires us to go deep into the problem and design new materials with atomic precision to come up with the right solution because traditional techniques are not going to work. The company hopes to be the first to commercialize metal-organic framework, or MOF, materials designed at the atomic level for hydrogen storage but isn’t alone in pursuing the technology. Scientists at Lawrence Berkeley National Laboratory recently published research on an aluminum-based MOF they’ve created to hold hydrogen, according to Science. (MOF, invented by cofounder Yaghi, is also the inspiration for the startup’s name, a mashup referencing the acronym and hydrogen.) Think of it as a novel combination of organic materials with some metal atoms A crystal structure at the nanoscale — at extremely small scale. Unlike carbon fiber-wrapped tanks used in Toyota’s Mirai fuel cell sedan that hold hydrogen at 10,000 pounds per square inch — the level of pressure that “jaws of life” tools use to cut through car doors — H2MOF intends to pressure its tank at less than 300 pounds per square inch. Storing more fuel at lower pressure means much less cost. Taha estimates that switching from high-pressure tanks to its technology could save $12,000 annually in energy expenses to operate a fuel cell transit bus. H2MOF’s technology could potentially double its 350-mile range per fueling by packing in more hydrogen without adding weight. Right now, hydrogen is pumped through pipelines in Texas and California, but they have to be made of materials that can withstand embrittlement and cracking that “slippery” hydrogen causes. Liquifying it is an easier way to transport the fuel, but is even more energy-intensive than storing it under high pressure. Ohnsman (2023) This Startup Hopes Its Nanomaterial Fuel Tanks Will Jumpstart The Hydrogen Revolution "],["military-technology.html", "9 Military Technology", " 9 Military Technology Smith Military technology is a hugely important area of innovation, and yet it generally results in things getting blown up and society going to hell for a while. Also worrying is how many of the new military technologies are specialized for use off the battlefield. In 2014, I wrote a post in which I argued that drone dominance of the battlefield would change human society forever: [I]magine yourself back in 1400. In that century (and the 10 centuries before it), the battlefield was ruled not by the infantryman, but by the horse archer—a warrior-nobleman who had spent his whole life training in the ways of war. Imagine that guy’s surprise when he was shot off his horse by a poor no-count farmer armed with a long metal tube and just two weeks’ worth of training. Just a regular guy with a gun. That day was the end of the Middle Ages and the beginning of modernity. For centuries after that fateful day, gun-toting infantry ruled the battlefield. Military success depended more and more on being able to motivate large groups of (gun-wielding) humans, instead of on winning the loyalty of the highly trained warrior-noblemen. But sometime in the near future, the autonomous, weaponized drone may replace the human infantryman as the dominant battlefield technology. And as always, that shift in military technology will cause huge social upheaval. Six years later, I watched my vision come true. In the Second Nagorno-Karabakh War, Azerbaijan used drones — purchased cheaply and easily from Turkey and Israel — to crush the vaunted Armenian army in a short space of time. Armenian troops were renowned as masters of infantry warfare and heavy weaponry, but their tanks, missile launchers, artillery, and transport vehicles were sitting ducks for their foes’ cheap disposable drones. No matter how well they concealed their vehicles, the drones could easily spot and destroy them. You can see the incredible toll catalogued at the blog Oryx, with full documentation of each destroyed vehicle. This should be as big a wakeup call as the Battle of Taranto or the firebombing of Guernica. Drones have changed warfare. Unless electronic countermeasures or directed energy weapons become very good, very fast, drones will scour the battlefield of human-controlled heavy weaponry at a very low cost, with little risk of life. And they create another battlespace to be fought over — the low-altitude air, where traditional piloted aircraft no longer go (for fear of being shot down), where radars have trouble spotting threats. Already countries are racing to build or buy cutting-edge drone systems; this is a true arms race. But we won’t know who wins that race unless and until there is a major war. But the real transformative drone technology might still be in its infancy. The drones that won the war for Azerbaijan are traditional fossil fuel powered aircraft. Advances in Li-ion batteries have given rise to small, cheap, difficult-to-see, difficult-to-shoot quadcopters. Already, militaries are finding creative uses for these: The IDF (Israel Army) has been using drones to drop tear gas on protesters in Ramallah and the West Bank. Another example is the UK, whose air force is testing networked swarms of drones to overwhelm radar systems. The disturbing possibility is that nations might simply exist in a state of low-grade cyberwarfare at all times, attempting to disable each other’s infrastructure. What COVID-19 made people realize was that you don’t need to create some super-deadly virus in order to severely disrupt a society. All you need is a very contagious disease with a mortality rate high enough to scare people. If you’re a very very unscrupulous country, you could surreptitiously vaccinate most of your population against this disease and then unleash it on the world. Crispr technology and DNA synthesis, which are increasingly available to the public, might conceivably create a lot of weird bioweapons that act very differently to the viruses we’re used to. Most of the modern military technologies led themselves to a very different kind of great-power war — a war of constant sniping and harassment. Assassin drones, cyberattacks, info ops, and bioweapons raise the possibility of never-ending low-grade attacks that are below the threshold of massive retaliation. To forestall this, military strategists should try very hard to think of new, robust, sophisticated methods of deterrence. Deterrence is the key to peace; it’s risky, but when it’s successful, it makes military technology act as a protector of human life rather than a destroyer of it. If new technology makes deterrence impossible, it might condemn us to a future where everyone is always on the offense. Noah Smith "],["semiconductors.html", "10 Semiconductors 10.1 N2 - Two Nanometer Chips", " 10 Semiconductors 10.1 N2 - Two Nanometer Chips Tooze Any company that opens up a technological lead in the next generation of advanced semiconductors will be well placed to dominate an industry that pulled in well over $500bn in global chip sales last year. That is projected to grow further due to a surge in demand for the data centre chips that power generative AI services. TSMC, which dominates the global market in processors, has already shown the process test results for its “N2” — or 2 nanometre — prototypes to some of its biggest customers, including Apple and Nvidia, according to two people with direct knowledge of the discussions. But two people close to Samsung said the Korean chipmaker was offering cut-price versions of its latest 2 nanometre prototypes in an effort to attract the interest of big-name customers including Nvidia. “Samsung sees 2 nanometre as a game-changer,” said James Lim, analyst at US hedge fund Dalton Investments. “But people are still doubtful it can execute the migration better than TSMC.” Tooze (2023) The next technological revolution "],["shipping.html", "11 Shipping 11.1 Windships", " 11 Shipping 11.1 Windships Gallucci This year’s forecast for the global maritime industry looks particularly breezy. Sails, kites, wings and tubes are all set to appear on cargo vessels over the course of 2022, harnessing wind energy to reduce ships’ use of dirty diesel fuels. Experts count nearly two dozen new projects in the works as shipping companies look to limit emissions from carrying cargo by sea. Gallucci (2022) Sailing into 2022 with wind-powered cargo ships "],["social-media.html", "12 Social Media 12.1 Twitter", " 12 Social Media 12.1 Twitter Noahpinion Dimensions Two years ago, my friend Eugene Wei wrote a blog post called “Status as a Service (Staas)”, which laid out what has become the canonical framework for thinking about social media. Eugene basically divides social media’s function into three dimensions — utility (i.e., direct usefulness), entertainment value, and social capital. He spends much of the post discussing the third of these — the way social networks create new ways for people to gain status and respect. Get the most Twitter follows, or the most Facebook likes, etc., and you’re somebody. Social media has democratized celebrity; anyone can be an influencer. Anyone, but not everyone. Just as most people can’t become Hollywood stars, most people can’t become social media influencers. But unlike in the old days, when people would obsess over Hollywood actors from afar, nowadays social media allows people to come in contact with their heroes directly. And no network facilitates this more than Twitter. I continue to believe that Twitter, alone among all social networks created thus far, represents something truly new under the sun. Facebook and LinkedIn more-or-less preserves the networks of personal friendship, hobby interest, and professional networking that exist offline. Instagram maintains the celebrity-fan dynamic, with influencers dominating their pages at an Olympian remove. But on Twitter, anyone can talk directly to anyone at any time, and, short of blocking them, the person they’re talking to can’t stop you from talking to them. On other social networks, if you created a post, you can delete comments that you don’t like; you are the moderator of your own threads. But on Twitter you can’t. There is a “hide replies” function, but it just sends the replies to a special “hidden replies” section where anyone can peruse them at will. Even if you block someone who replies to you, their reply-tweet remains. These two quirks of Twitter — free direct communication and no ability to regulate replies — make all the difference. Suddenly, people can talk directly to any celebrity, any politician, any journalist or activist or influencer of any kind. And the person they’re talking to can’t stop them. Being able to reply to high-status people, whether they want you to or not, is a heady status-conferring experience. You can say mean shit to the most famous Hollywood movie star, and there’s nothing he can do about it. Or you can say something nice, and hopefully get a reply or a shout-out. This puts you on a plane of near-equality with people who otherwise tower over the social landscape. Near-equality, but not equality! This can be maddening. Twitter creates the instantaneous illusion of social equality between influencers and normal people. That process, which repeats itself many millions of times every day, creates some very unusual social dynamics. For example, there’s “the ratio”, in which a mob of reply-tweeters try to leave someone with more replies than likes. It feels heady to be part of a ratio-mob, as evidenced by the people who reply with “just here for the ratio”, or who re-state a rebuttal that many others have already made. (Some people have invented a second type of “ratio” that doesn’t depend on being part of a mob: writing a reply-tweet that gets more likes than the original tweet it’s replying to. I’ve seen Zoomers in group chats bragging about the famous people they managed to “ratio” this way.) By bringing people much closer together in social status, Twitter emphasizes the intractable gaps that remain. As Twitter ages and the distribution of status gets even more frozen in, Twitter will have to rely on status anxiety more and more to keep new users engaged. They’ve never taken the crucial step of allowing people to actually drop reply-tweets from their threads or untag themselves from other people’s tweets. Doing that might make Twitter a lot nicer of a place Thus, Twitter will continue to be the place where Americans go to scream at strangers — where status is conferred not just by little snippets of viral pseudo-wisdom, but by the ability to ridicule and attack those snippets. We should probably think long and hard about whether it’s a good idea to have our public discourse dominated and directed by a platform with that basic dynamic. Noahpinion (2021) Status Anxiety as Service "],["steel.html", "13 Steel", " 13 Steel Today, the U.S. only accounts for about 5 percent of global steel production capacity. If the U.S. is to achieve Biden’s vision of a new deal for America, complete with infrastructure upgrades, domestically sourced materials and net-zero emissions, the country needs not only to reverse its flagging fortunes in the steel market but also to foster new technologies that will enable it to produce “green” steel with a minimum of carbon dioxide emissions. Such new technologies are now under development, although their entry into the marketplace is going to require time, investment and government support. Steel production is one of humanity’s most environmentally destructive activities. Even in its diminished state, the U.S. steel industry releases more carbon dioxide emissions than any other domestic industry — nearly a ton of carbon dioxide for every ton of steel produced. That’s largely because steel-making relies on coal and natural gas for most of its hefty energy consumption. Steel industry emissions must be mitigated at first by eking out small improvements to a wide variety of production stages. Simply using steel more efficiently is the first step. For example, some new forms of concrete are structurally stable without the use of steel reinforcing bars. Also, other materials can be substituted for steel; one young company called Inventwood is developing a process that transforms wood into a material strong enough to be used in place of steel. Another technique is to recycle more steel. According to the International Energy Agency, producing steel from recycled scrap requires only one-eighth the energy associated with producing steel from iron ore. Scrap accounts for about 70 percent of the raw metal input to U.S. steel production today, a figure that can be boosted. But that alone won’t obviate the need for new steel mills, since future demand for steel will outpace past supply. Instead, the U.S. will have to make new steel from iron ore and mitigate the emissions stemming from that process. To better understand the options for improvement, let’s review how steel is typically made. First, iron ore and fossil fuels (usually either specially refined coal or natural gas) are put in a furnace, where the fuels are burned to produce heat, carbon monoxide and carbon dioxide. The carbon monoxide combines with oxygen from the iron oxide contained in the ore, forming carbon dioxide and leaving behind a quantity of nearly pure iron. That iron is then conveyed either to a specially lined vat where oxygen is blown through liquid iron or to an electric furnace. In these secondary vessels, the iron is further purified and combined with small amounts of carbon to make steel. One way to mitigate the carbon emissions from this process is to capture carbon dioxide from the furnace and sequester it in underground reservoirs. Most carbon-capture facilities don’t actually sequester the carbon dioxide they capture. Instead, they sell it to oil companies that then pump it underground to force oil to the surface, a process known as enhanced oil recovery (EOR). The only operating steel plant using carbon capture at scale, the Al Reyadah plant in Abu Dhabi, employs this technique. It’s not clear that EOR sequestration actually reduces emissions on a net basis if the calculation includes the carbon dioxide released by burning the oil that’s produced. It’s unlikely this technique will result in significant reductions of net emissions. Other techniques include improving the efficiency of the ore processing furnaces and replacing coal furnaces with natural-gas furnaces. These techniques will only provide marginal emission reductions. New steel-making technologies H2 DRI The two leading steel-making technologies with the potential to nearly eliminate carbon dioxide emissions use a common chemical process known as electrolysis. One technology that’s well on its way is called “hydrogen direct reduced iron” (H2 DRI). It is now being demonstrated in Sweden, Japan and Germany. H2 DRI substitutes hydrogen (preferably, but not necessarily, made with clean energy) for the coal or natural gas used in the typical furnace process. In a DRI furnace, the iron ore is heated but not to the point of melting. Hydrogen then passes over the hot ore, combining with oxygen liberated from the iron oxide to form water and leaving relatively pure iron behind. Typically, that still-hot iron is then transferred to an electric furnace for additional processing to turn it into steel. If the electricity used to produce the hydrogen and run the furnace comes from non-carbon-emitting sources, then the overall process results in little to no carbon dioxide emissions. In Sweden, a joint venture dubbed Hybrit (comprising utility Vattenfall, iron ore processor LKAB and steel maker SSAB) is running a pilot H2 DRI plant. This spring, it started to use hydrogen produced via electrolysis from electricity generated by fossil-free sources. (This being Sweden, those probably consist of nuclear and hydropower, with a bit of wind power sprinkled in.) Building a full-scale H2 DRI plant, including electrolyzers to produce hydrogen from clean electricity, costs billions of dollars, and the process consumes prodigious amounts of electricity. Its economics strongly depend on the cost of that electricity and the value of the avoided carbon dioxide emissions. According to the consultancy McKinsey, H2 DRI is not expected to be cost-effective in Europe until sometime between 2030 and 2040. MOE The other technology under development, molten oxide electrolysis (MOE), also employs electrolysis. But in this case, it’s applied directly to the iron oxide ore by placing it in an electrolytic cell filled with a mineral-bearing solution. An electric current is run through the solution, heating it up beyond the melting point of iron, and separating oxygen from iron. If the electricity used to power the MOE process comes from clean sources, the steel can be made with virtually no carbon dioxide emissions. In the U.S., MOE is being developed by Boston Metal, a company spun out of the Massachusetts Institute of Technology. Like H2 DRI, MOE economics are heavily dependent on the cost of clean electricity. Boston Metal is currently gearing up to build its first pilot plant in Massachusetts, and it is looking into building a larger facility in Quebec or another location with cheap hydroelectricity. Prospects Of the two technologies, H2 DRI is clearly further along, with a pilot plant in operation and a full-scale plant in development. MOE has some intriguing advantages for the U.S. market, however. First, it’s more efficient, requiring somewhere between 15 and 30 percent less electricity than H2 DRI per ton of steel output. Second, MOE facilities can be constructed in much smaller increments than H2 DRI, although exactly how small isn’t clear just yet. That’s a big deal in the U.S., where a diminished steel industry is unlikely to invest billions of dollars for a new steel plant based on new technology. Furthermore, Boston Metal’s electrolysis cells are so clean that developers would have far more flexibility in where they’re located. For example, they could be placed near inexpensive sources of clean electricity or iron ore, or maybe even in Pittsburgh. Both technologies are going to take at least a decade before they’re ready to start claiming significant amounts of market share, but over the long run, the odds of Boston Metal’s MOE technology gaining traction in the U.S. market appear to be better. Because steel constitutes just a small portion of most products of which it’s a component, that price premium is likely to be small. For example, the International Energy Agency estimates that using green steel would increase the cost of a midsized car by around 0.1% CanaryMedia "],["supply-chain.html", "14 Supply Chain", " 14 Supply Chain Smith Ocean freight costs alone add 5% to 10% to the cost of everything we buy, and remember, 90% of the stuff we buy is shipped on a container ship. The globalized supply chain and shipping containers have brought down the cost of shipping goods and manufacturing by close to 90% over the last 50 years. In America, the ports are owned by the local city that they’re in. Therefore, they’re not managed as a strategic national asset, which they clearly are. We’ve under invested in our supply chain infrastructure for over 20 years. In hindsight, the signs were there for years. Almost no logistics companies can show you where your freight is in real-time on a map. Most data is exchanged in unstructured email messages with attachments. There are almost no logistics APIs to speak of. We’re going to get sub-optimal outcomes if you don’t invest in technology. If we don’t have robotics, if we don’t have systems that are better at managing appointments for managing pickups and returns of containers at ports, if we don’t have better safety mechanisms (some of these are incredibly hazardous jobs and robots would be far safer), it’s going to take many years, not months to fix this crisis. Technology and automation have helped modernize and increase the efficiency of ports in other countries like the port of Rotterdam in the Netherlands, but that’s because it’s managed as a strategic asset for the country. It has been a fully automated operation for over 20 years so the technology exists, but we still have a lack of investment to implement those changes in the United States. N.S.: What should the Biden administration have done to overwhelm supply chain bottlenecks early on in the crunch? What should the administration be doing now? R.P.: I think many of us imagined that we live in a world where there’s a wizard behind the box. That there’s actually somebody in charge of all of this, and that that somebody must have made a mistake. And of course, it must be the president of the United States. But that’s not actually the world that we live in. It’s a market-based system. We’re lucky to live in an economy that’s built on the principles of free enterprise, and so while it’s easy to cast blame and point fingers at the administration, we have to recognize that they’re not really in charge of all of these things. They didn’t create this situation and I’m not 100% convinced that they’re the ones that are going to be best equipped to solve the problem. N.S.: Was the global economy simply over-engineered? Did we optimize supply chains for efficiency at the cost of resilience, like a machine with tolerance gaps that are too small? And if so, should we recalibrate going forward, to leave more slack in the system in case of future crises? R.P.: In my opinion, what’s caused all the supply chain bottlenecks is modern finance’s obsession with Return on Equity (ROE). To show great ROE, almost every CEO stripped their company of all but the bare minimum of assets. “Just-in-time” everything with no excess capacity, no strategic reserves, no cash on the balance sheet and minimal investment in R&amp;D. We stripped the shock absorbers out of the economy in pursuit of better short-term metrics. Large businesses are supposed to be more stable and resilient than small ones, and an economy built around giant corporations like America’s should be more resilient to shocks. However, the obsession with ROE means that no company was prepared for the inevitable hundred-year storms. Now as we’re facing a hundred-year storm of demand, our infrastructure simply can’t keep up. And let’s not forget the human aspect of the workforce that makes this all happen. A lot of companies in the industry haven’t invested in taking care of their people, especially during market downturns, so now they can’t staff up quickly to meet surging demand. The Dutch government has pushed for infrastructure innovation for decades and has a great working relationship with unions and employers through a polder model, which is based on consensus. This effort was started in the eighties. They used the polder model to successfully implement solutions developed by Delft University of Technology. There were two reasons they were able to accomplish this: The Port of Rotterdam, a government-owned commercial entity running the port, had this vision way before other countries did as logistics is a key source of GDP in the Netherlands. They had a proper, documented approach to getting buy-in from multiple stakeholders through a polder model. The polder model is a method of consensus decision-making, based on the acclaimed Dutch version of consensus-based economic and social policy making in the 1980s and 1990s. The model is characterized by the cooperation between employers&#39; organizations, labor unions and the government with a central forum to discuss labor issues (with a long tradition of consensus). This model helped them defuse labor conflicts and avoid strikes. Similar models are used in Finland. We should really explore why the U.S. can’t do what many mature and rapidly-growing economies already have. Big structural changes are hard to make, but we should at least start somewhere. For example, new technology can be used to eliminate appointments at terminals and allow truck drivers to just show up and take the first available container with a mobile app telling them where to go. We’ve already built this technology and it’s ready to go right now and we believe it could clear the backlog at the Long Beach/Los Angeles ports within 30 days. However, it requires changes to contracts of who’s responsible for picking up which container and a lot of coordination between the private sector, trucking companies, importing businesses, warehouses, ports and ocean carriers. This type of coordination is inherently difficult for the private sector to coordinate, where each is looking out for their own best interests. Smith (2021) Interview: Ryan Petersen, founder and CEO of Flexport "],["wood.html", "15 Wood 15.1 Transparent Wood", " 15 Wood Architects and developers are increasingly aware of the role played by steel and concrete manufacturing in the worsening climate crisis, and there is already a move in some quarters towards much more sustainable building materials. One such material is already being widely used in construction, but recent advances mean it is stronger and more durable than it has ever been before, and has a far, far lower environmental impact than concrete or steel. That material is wood. Though timber-framed buildings are hardly new, instead of sawing enormous beams from ancient trees, new techniques focus on using fast-growing soft woods, stuck together in a form which provides massive strength, durability, and flexibility of design. One example of this, cross-laminated timber (CLT), is manufactured using a technique developed in the 1990s in Austria, in which sheets of kiln-dried wood are glued on top of each other, with the grain of each layer running perpendicular to the next. This method can create huge boards, up to a foot thick, and as long and as wide as the manufacturer’s premises allow. What’s more, the strength of these coagulated timber slabs can match or exceed steel or concrete. The use of CLT as a modern construction material has already been definitively proven. The world’s largest CLT structure is Dalston Works, a 10-storey residential building of 101 flats, in Hackney, London, which was completed in 2017, and won the “eco living award” at the Evening Standard’s 2018 New Homes Awards. Meanwhile, the world’s tallest timber building has also been built using CLT – the 85.4-metre, 18-storey Mjostarnet building in Norway, which was completed in 2019 and is also the country’s third-tallest building. The mixed-use building contains apartments, a hotel, a swimming pool, office space and a restaurant. Figure: Mjøstårnet For new buildings, the energy regulations are pushing energy consumption and carbon emissions down to the point that the main carbon emissions from new buildings through their life cycle come from their construction and materials. CLT buildings may be able to store more carbon in the wood than their entire construction generates. As trees absorb CO2 when they grow, CLT is considered to have a negative embodied carbon – meaning that the CO2 absorbed by the tree during its growth can be more than that emitted in the manufacture of the CLT product and its transportation to the site. At the end of its useful life CLT can be repurposed – something tricky to achieve with other building materials. The timber used should come from managed forests which have been properly certified as being sustainable sources of wood. However, “sustainable forestry” is a contentious subject, with different meanings in different countries. While vast forests of fast-growing conifers may be able to rapidly fulfil timber orders, a growing understanding of the impact of monoculture cropping on biodiversity, and what it means for carbon sequestration, is also a key consideration for those seeking to herald CLT as a straightforward environmentally friendly choice. The wood used in the 10-storey Dalston Works building in London was grown in forests in Austria and Germany which have been certified as sustainable. It was then manufactured into CLT in Austria and brought by road to the UK. According to the developers, the building used 4,500 cubic metres of timber, which equates to about 2,300 trees. With more than 800 people living in the building, they say it worked out at about three trees per person. the main tree grown for construction in the UK is the sitka spruce, an imported conifer from the Pacific northwest of North America. In their home region these trees can reach 40-70 metres in height, but in the UK, where conditions are milder, their growth rate is faster but the resulting density of the wood is lower, making it weaker. As a result, higher strength timber grown in Europe is normally used for key structural purposes. One particular concern about the extensive use of wood in construction is the potential for flammability. In order to be used as a commercial construction material, CLT has been extensively fire-tested, and is designed to accommodate substantial fire resistance. Furthermore, unlike steel, CLT remains structurally stable when subjected to high temperatures. CLT is green, cost-effective, fast to install, requires less foundation, and results in less waste than traditional construction. From Comments It is incorrect to say that CLT “unlike steel” remains structurally stable to high temperatures. Steel used in buildings retains at least 100% of its cold strength up to about 360°°C. (It’s actually stronger at around 150-300°C.) What is true is that its insulation properties causes wood to degrade more slowly when exposed to heat as the heat doesn’t penetrate so fast. Which is why steam boilers are made out of steel and not wood Cockburn 15.1 Transparent Wood Coleman Transparent wood could soon find uses in super-strong screens for smartphones; in soft, glowing light fixtures; and even as structural features, such as color-changing windows…. Wood is made up of countless little vertical channels, like a tight bundle of straws bound together with glue. These tube-shaped cells transport water and nutrients throughout a tree, and when the tree is harvested and the moisture evaporates, pockets of air are left behind. To create see-through wood, scientists first need to modify or get rid of the glue, called lignin, that holds the cell bundles together and provides trunks and branches with most of their earthy brown hues. After bleaching lignin’s color away or otherwise removing it, a milky-white skeleton of hollow cells remains. This skeleton is still opaque, because the cell walls bend light to a different degree than the air in the cell pockets does—a value called a refractive index. Filling the air pockets with a substance like epoxy resin that bends light to a similar degree to the cell walls renders the wood transparent. The material the scientists worked with is thin—typically less than a millimeter to around a centimeter thick. But the cells create a sturdy honeycomb structure, and the tiny wood fibers are stronger than the best carbon fibers, says materials scientist Liangbing Hu, who leads the research group working on transparent wood at the University of Maryland in College Park. And with the resin added, transparent wood outperforms plastic and glass: In tests measuring how easily materials fracture or break under pressure, transparent wood came out around three times stronger than transparent plastics like Plexiglass and about 10 times tougher than glass. ‘The results are amazing, that a piece of wood can be as strong as glass,’ says Hu, who highlighted the features of transparent wood in the 2023 Annual Review of Materials Research. Coleman (2023) Why scientists are making transparent wood "],["science.html", "16 Science 16.1 Science Slowdown", " 16 Science 16.1 Science Slowdown Noah Smith Low-hanging fruit and the rising cost of science The basic idea of science stagnation is that the easiest discoveries happen first. 150 years ago, a monk sitting around playing with plants was able to discover some of the most fundamental properties of inheritance; now, biology labs are gigantic and hugely expensive marvels of technological complexity, and the NIH spends tens of billions of dollars every year. 400 years ago we had people rolling balls down ramps to study gravity; now we study gravity with billion-dollar gravitational wave detectors that require the efforts of thousands of highly trained scientists. And so on. In 2020, four economists — Nicholas Bloom, Charles I. Jones, John Van Reenen, and Michael Webb — published a paper quantifying this principle, and the results are deeply disturbing. Across a wide variety of fields, they found that the cost of progress has been rising steadily; more and more researchers (or “effective researchers”) are required for each incremental advance. This is exactly what a “low-hanging-fruit” model of science would predict. The idea of increasingly expensive research, unlike the other stagnationist arguments I addressed in earlier posts, is very hard to rebut — the theory is simple and powerful and the data is comprehensive and clear. But there are a few caveats to note here. Important discoveries become more important as they age. Quantum mechanics was certainly cool stuff back in the 1920s, but it wasn’t until later that things like quantum field theory built on it, or engineering applications were developed that made use of it. Science is progressive like that; each discovery is supported by the discoveries that came before it (in Newton’s words, it “stands on the shoulders of giants”). Thus, each new discovery makes the older discoveries that support it that much more important. The upshot here is that even if science is getting more expensive, we can still afford to spend more resources and sustain it for a while. Jones and Summers make a simple model of the economy in which R&amp;D spending drives growth, plug recent numbers for our real economy into that model, and then ask how much it would reduce growth if we were to stop spending on R&amp;D. The answer is: A lot. R&amp;D is a reliable money-printing machine: you put in a dollar, and you get back out much more than a dollar. Clancy links us to a bit of evidence that R&amp;D spending still drives progress forward, explaining the results of several papers that find that government research grants to small businesses were very effective at creating patentable inventions in both the U.S. and the EU. Business is running fast enough to stay in place in terms of R&amp;D, but the government isn’t even doing that much. The upshot of all this is that while the increasing cost of science is a real and significant concern, it doesn’t mean it’s all stagnation from here on out. We still probably have enough money to accelerate technological progress once again, if we’re willing to spend it. Noah Smith (2021) "],["ai.html", "17 AI", " 17 AI AI is rapidly taking over the world of venture finance, with more than a quarter of VC money now flowing into the space. (2023) Smith AI coming A whole lot of research is being done on the productivity effects of generative AI tools, and they all seem to conclude the same thing: Generative AI gives a much bigger boost to low performers than to high performers. No study so far showing that more talented people are able to use generative AI more effectively than less talented people. All of the evidence points to generative AI as an equalizer. It’s not hard to think of why this might be the case. Whereas previous forms of information technology complemented human cognition, generative AI tends to substitute for human cognition. Traditional IT acted like a shovel — something that complemented people’s natural abilities — while generative AI acts more like a steam shovel. A steam shovel handles the muscle-power for you; GPT-4 handles the detail-oriented thinking for you. Technologies that substitute for natural ability tend to make natural ability less scarce, and therefore less valuable. This doesn’t mean generative AI will decrease inequality overall. The computation-intensive nature of these tools means that physical capital — access to large amounts of cheap GPUs or other key hardware — might make a comeback as a source of wealth. But by boosting the performance of the least skilled on cognitive tasks, generative AI looks like it could level the human-capital playing field. In order to program computers the traditional way, or even to apply lots of kinds of software, you had to have a mind that could think like a computer. But generative AI is specifically set up to interface with people who don’t think like machines. GPT-4 handles the detail-oriented thinking for you. The computation-intensive nature of these tools means that physical capital — access to large amounts of cheap GPUs or other key hardware — might make a comeback as a source of wealth. But by boosting the performance of the least skilled on cognitive tasks, generative AI looks like it could level the human-capital playing field. Abundant energy complements average people’s skills. Energy that’s both cheap and widely portable will enable all sorts of economic activity that average people will be easily able to master. Battery-powered appliances and industrial tools, robots that can be ordered around with generative AI, cheap chemical manufacturing and earth moving, fast efficient vehicles with long ranges, 3d printers, and so on. The power of every construction worker and factory worker and food delivery worker and nurse will be magnified by the new energy abundance. []/fig/Energy_use_per_capita_1800-2010.png) Cheaper, more portable energy seems like it’ll help put us back on a technology curve more like the one we were on before the 70s. The Revenge of the Normies thesis is, of course, an exercise in optimism. As flattering as the age of human capital was for my nerdy tribe, such a small slice of society shouldn’t be the only ones who get to thrive. We’ve had a four-decade-long celebration and veneration of talent and excellence in America; we could use an equally long period where the vast middle class and working class are the people who reap the most rewards. Smith (2023) Is it time for the Revenge of the Normies Smith AI Risks Thinking AI risk thinkers were always able to come up with lots of scary sci-fi scenarios about how generative AI could cause a global calamity. Those scenarios weren’t obviously impossible; it’s clear that they’re worth worrying about. But when it came to recommendations for policy to diminish the risk of these scenarios becoming reality, the AI risk people were always short on actionable ideas. You can study how AI models work and try to understand them — Anthropic and others are working on interpretability. But because the really scary doomsday scenarios all depend on AI that’s much more advanced than what exists today, knowledge about how AI works now won’t necessarily help us avert those possibilities. The people who are scared of AI doomsday risk tend to believe in a “fast takeoff” in which AI goes very very rapidly from the GPT-style chatbots we know today to something more like Skynet or the Matrix. It’s basically a singularity argument: The technological singularity—or simply the singularity[1]—is a hypothetical future point in time at which technological growth becomes uncontrollable and irreversible, resulting in unforeseeable consequences for human civilization. According to the most popular version of the singularity hypothesis, I. J. Good’s intelligence explosion model, an upgradable intelligent agent will eventually enter a “runaway reaction” of self-improvement cycles, each new and more intelligent generation appearing more and more rapidly, causing an “explosion” in intelligence and resulting in a powerful superintelligence that qualitatively far surpasses all human intelligence. “Fast takeoff” means that A) we basically can’t know much if anything about what AI will be like by the time it becomes truly scary, and B) it could jump to “truly scary” level at any minute. Thus the only action that most of the prominent AI risk people have been able to advise us to do is to “shut it all down” — to simply not make better AI. A permanent halt to AI development simply isn’t something AI researchers, engineers, entrepreneurs, or policymakers are prepared to do. I see this as another case of a modern intellectual movement that is far better at identifying problems than it is at suggesting solutions. My prediction is that basically all of these movements will attract a lot of initial attention, but then gradually be ignored over time. The AI scenarios that EA folks suggest certainly are scary. But until EA comes up with some solution other than “shut it all down”, the people developing AI are simply going to pray for the serenity to accept the things they cannot change. Smith (2023) At least five things for your Thanksgiving weekend "],["about.html", "A About", " A About Dyre Haugen and Dyrehaugen is Webian for Jon Martin - self-owned Globian, Webian, Norwegian and Canarian with a background from industrial research policy, urban planning and economic development consulting on global, regional and urban scales. I am deeply concerned about the (insane) way humanity (i.e. capitalism) interfere with nature. In an effort to gain insights in how and why this happens stuff is collected from around the web and put together in a linked set of web-sites. The sites are operated as personal notebooks. However, these days things can be easily published to the benefit of others concerned with the same issues. But be aware - this is not polished for presentation or peer-reviewed for exactness. I offer you just to have a look at my ‘work-desk’ as it appears in the moment. Any comment or suggestion can be mailed to dyrehaugen@gmail.com You can follow me on twitter as @dyrehaugen. Thanks for visiting! "],["links.html", "B Links", " B Links Current Dyrehaugen Sites: rcap - On Capitalism (loc) rclm - On Climate Change (loc) recs - On Economics (loc) rfin - On Finance (loc) rngy - On Energy (loc) renv - On Environment (loc) rsts - On Statistics (loc) rurb - On Urbanization (loc) rvar - On Varia (loc) rwsd - On Wisdom (loc) Blogs: rde - Blog in English (loc) rdn - Blog in Norwegian (loc) Discontinued: jdt - Collection (Jekyll) (loc) hdt - Collection (Hugo) (loc) Not listed: (q:) dhe dhn jrw56 (z:) rcsa rpad rstart "],["news.html", "C NEWS", " C NEWS "],["sitelog.html", "D Sitelog", " D Sitelog Latest Additions December 12, 2023 semiconductor\\        the nanoscale environment N2 chips December 18, 2023 wood\\        transparent wood December 21, 2023 graphene\\        paragraf cambridge graphene microchips "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
